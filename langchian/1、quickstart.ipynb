{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True)\n",
    "\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# print(DeepSeek_API_KEY)  # å¯ä»¥é€šè¿‡æ‰“å°æŸ¥çœ‹ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f2439",
   "metadata": {},
   "source": [
    "## è°ƒç”¨DeepSeekçš„APIï¼Œç”Ÿæˆå›ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6450cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œç”±å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯é©±åŠ¨ï¼Œæ—¨åœ¨ä¸ºä½ æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜æˆ–ååŠ©å®Œæˆå„ç§ä»»åŠ¡ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ ï¼š\n",
      "\n",
      "1. **å›ç­”é—®é¢˜**ï¼šæ¶µç›–ç§‘å­¦ã€å†å²ã€æ–‡åŒ–ã€æŠ€æœ¯ç­‰å¤šä¸ªé¢†åŸŸã€‚  \n",
      "2. **æä¾›å»ºè®®**ï¼šæ¯”å¦‚å­¦ä¹ ã€æ—…è¡Œã€ç”Ÿæ´»æŠ€å·§ç­‰ã€‚  \n",
      "3. **ååŠ©åˆ›ä½œ**ï¼šå†™ä½œã€ç¿»è¯‘ã€ç”Ÿæˆåˆ›æ„å†…å®¹ç­‰ã€‚  \n",
      "4. **è§£å†³é—®é¢˜**ï¼šé€»è¾‘åˆ†æã€æ•°å­¦è®¡ç®—ã€ç¼–ç¨‹è¾…åŠ©ç­‰ã€‚  \n",
      "5. **æ—¥å¸¸èŠå¤©**ï¼šåˆ†äº«æƒ³æ³•æˆ–é—²èŠæ”¾æ¾ã€‚\n",
      "\n",
      "æˆ‘çš„çŸ¥è¯†æˆªæ­¢äºæœ€æ–°æ›´æ–°çš„æ•°æ®ï¼Œä¸”ä¼šå°½åŠ›æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯ã€‚å¦‚æœä½ æœ‰ä»»ä½•éœ€æ±‚æˆ–ç–‘é—®ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ï¼ ğŸ˜Š\n",
      "\n",
      "ä½ æƒ³å…ˆä»ä»€ä¹ˆå¼€å§‹å‘¢ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# åˆå§‹åŒ–DeepSeekçš„APIå®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# è°ƒç”¨DeepSeekçš„APIï¼Œç”Ÿæˆå›ç­”\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# æ‰“å°æ¨¡å‹æœ€ç»ˆçš„å“åº”ç»“æœ\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af8dd1",
   "metadata": {},
   "source": [
    "## åœ¨ LangChain ä¸­è°ƒç”¨DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da338e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# æ–¹å¼Aï¼šæ˜¾å¼å£°æ˜ provider\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "# æ–¹å¼Bï¼šåˆå¹¶å†™æ³•ï¼ˆä¹Ÿå¯åœ¨å…¶ä»–å‚å•†ä½¿ç”¨ï¼‰\n",
    "# llm = init_chat_model(\"deepseek:deepseek-chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5605522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e1c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "result = model.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa90977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
       "\n",
       "æˆ‘æ˜¯DeepSeekï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ã€‚è®©æˆ‘æ¥è¯¦ç»†ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\n",
       "\n",
       "**æˆ‘çš„ç‰¹ç‚¹ï¼š**\n",
       "- ğŸ’¬ æˆ‘æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æ¨¡å‹ï¼Œæ“…é•¿ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€\n",
       "- ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½â€”â€”å¯ä»¥å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ–‡ä»¶ï¼Œå¹¶ä»ä¸­è¯»å–æ–‡å­—ä¿¡æ¯\n",
       "- ğŸŒ å…·å¤‡è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆéœ€è¦ä½ åœ¨Web/Appä¸­æ‰‹åŠ¨å¼€å¯ï¼‰\n",
       "- ğŸ’¾ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½è®°ä½æˆ‘ä»¬å¯¹è¯ä¸­çš„å¾ˆå¤šç»†èŠ‚\n",
       "\n",
       "**æˆ‘èƒ½ä¸ºä½ åšä»€ä¹ˆï¼š**\n",
       "- å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›çŸ¥è¯†è§£ç­”\n",
       "- ååŠ©å†™ä½œã€ç¿»è¯‘ã€æ€»ç»“æ–‡æ¡£\n",
       "- è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ†æ\n",
       "- åˆ›æ„å†™ä½œå’Œå¤´è„‘é£æš´\n",
       "- å­¦ä¹ è¾…å¯¼å’ŒçŸ¥è¯†è§£é‡Š\n",
       "- æ—¥å¸¸èŠå¤©å’Œæƒ…æ„Ÿæ”¯æŒ\n",
       "\n",
       "**é‡è¦æé†’ï¼š**\n",
       "- æˆ‘å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’\n",
       "- ç›®å‰ä¸æ”¯æŒè¯­éŸ³åŠŸèƒ½\n",
       "- ä½ å¯ä»¥é€šè¿‡å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½Appæ¥ä½¿ç”¨æˆ‘\n",
       "\n",
       "æˆ‘çš„çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæƒ³èŠçš„æˆ–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿæˆ‘å¾ˆä¹æ„ä¸ºä½ æœåŠ¡ï¼âœ¨"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e33b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\\n\\næˆ‘æ˜¯DeepSeekï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ã€‚è®©æˆ‘æ¥è¯¦ç»†ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\\n\\n**æˆ‘çš„ç‰¹ç‚¹ï¼š**\\n- ğŸ’¬ æˆ‘æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æ¨¡å‹ï¼Œæ“…é•¿ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€\\n- ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½â€”â€”å¯ä»¥å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ–‡ä»¶ï¼Œå¹¶ä»ä¸­è¯»å–æ–‡å­—ä¿¡æ¯\\n- ğŸŒ å…·å¤‡è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆéœ€è¦ä½ åœ¨Web/Appä¸­æ‰‹åŠ¨å¼€å¯ï¼‰\\n- ğŸ’¾ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½è®°ä½æˆ‘ä»¬å¯¹è¯ä¸­çš„å¾ˆå¤šç»†èŠ‚\\n\\n**æˆ‘èƒ½ä¸ºä½ åšä»€ä¹ˆï¼š**\\n- å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›çŸ¥è¯†è§£ç­”\\n- ååŠ©å†™ä½œã€ç¿»è¯‘ã€æ€»ç»“æ–‡æ¡£\\n- è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ†æ\\n- åˆ›æ„å†™ä½œå’Œå¤´è„‘é£æš´\\n- å­¦ä¹ è¾…å¯¼å’ŒçŸ¥è¯†è§£é‡Š\\n- æ—¥å¸¸èŠå¤©å’Œæƒ…æ„Ÿæ”¯æŒ\\n\\n**é‡è¦æé†’ï¼š**\\n- æˆ‘å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’\\n- ç›®å‰ä¸æ”¯æŒè¯­éŸ³åŠŸèƒ½\\n- ä½ å¯ä»¥é€šè¿‡å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½Appæ¥ä½¿ç”¨æˆ‘\\n\\næˆ‘çš„çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæƒ³èŠçš„æˆ–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿæˆ‘å¾ˆä¹æ„ä¸ºä½ æœåŠ¡ï¼âœ¨', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 10, 'total_tokens': 257, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 10}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '3e42b190-a6f5-4ddc-afc8-f87711d102f8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4dabe111-2a9d-482a-a022-de112dbc4c96-0', usage_metadata={'input_tokens': 10, 'output_tokens': 247, 'total_tokens': 257, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ba011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refusal': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.additional_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14fd76",
   "metadata": {},
   "source": [
    "## é“¾å¼è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a604b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“ç„¶ï¼Œé«˜æ•ˆé˜…è¯»è®ºæ–‡ä¸ä»…èƒ½èŠ‚çœæ—¶é—´ï¼Œè¿˜èƒ½å¿«é€ŸæŠ“ä½æ ¸å¿ƒå†…å®¹ã€‚ä»¥ä¸‹æ˜¯ä¸‰æ¡å®ç”¨è¦ç‚¹ï¼š\n",
      "\n",
      "1. **é‡‡ç”¨ä¸‰éé˜…è¯»æ³•ï¼Œå±‚å±‚æ·±å…¥**  \n",
      "   - **ç¬¬ä¸€é**ï¼šå¿«é€Ÿæµè§ˆæ ‡é¢˜ã€æ‘˜è¦ã€å›¾è¡¨å’Œç»“è®ºï¼Œåˆ¤æ–­è®ºæ–‡æ˜¯å¦ç›¸å…³ï¼Œå†³å®šæ˜¯å¦ç»§ç»­é˜…è¯»ã€‚  \n",
      "   - **ç¬¬äºŒé**ï¼šç²¾è¯»å¼•è¨€ã€æ–¹æ³•ã€ç»“æœï¼Œæ ‡è®°å…³é”®ä¿¡æ¯ï¼Œå¿½ç•¥ç»†èŠ‚æ¨å¯¼ã€‚  \n",
      "   - **ç¬¬ä¸‰é**ï¼šå¤ç°ä½œè€…æ€è·¯ï¼Œæ·±å…¥ç†è§£å®éªŒè®¾è®¡å’Œè®ºè¯é€»è¾‘ï¼Œæå‡ºæ‰¹åˆ¤æ€§é—®é¢˜ã€‚  \n",
      "\n",
      "2. **å¸¦ç€é—®é¢˜ä¸»åŠ¨é˜…è¯»ï¼Œé¿å…è¢«åŠ¨æ¥æ”¶**  \n",
      "   - è¾¹è¯»è¾¹é—®ï¼šâ€œç ”ç©¶è§£å†³äº†ä»€ä¹ˆç¼ºå£ï¼Ÿâ€â€œæ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨å“ªï¼Ÿâ€â€œæ•°æ®æ˜¯å¦æ”¯æ’‘ç»“è®ºï¼Ÿâ€  \n",
      "   - ç”¨ç¬”è®°å·¥å…·ï¼ˆå¦‚MarginNoteæˆ–è¡¨æ ¼ï¼‰æ•´ç†â€œé—®é¢˜-ç­”æ¡ˆ-ç–‘ç‚¹â€ï¼Œå½¢æˆäº’åŠ¨å¼é˜…è¯»ä¹ æƒ¯ã€‚  \n",
      "\n",
      "3. **å–„ç”¨å·¥å…·ä¸åä½œï¼Œæå‡æ•ˆç‡**  \n",
      "   - ç”¨AIå·¥å…·ï¼ˆå¦‚ChatGPTï¼‰å¿«é€Ÿè§£æå¤æ‚æ®µè½ï¼Œæˆ–ç”¨ç¿»è¯‘å·¥å…·çªç ´è¯­è¨€éšœç¢ã€‚  \n",
      "   - ä¸åŒè¡Œè®¨è®ºè®ºæ–‡ç–‘ç‚¹ï¼Œé€šè¿‡å¤è¿°å’Œè¾©è®ºå·©å›ºç†è§£ï¼Œé¿å…é™·å…¥æ€ç»´ç›²åŒºã€‚  \n",
      "\n",
      "**é™„åŠ æŠ€å·§**ï¼šä¼˜å…ˆé˜…è¯»é«˜å¼•è®ºæ–‡å’Œæƒå¨å›¢é˜Ÿçš„ç»¼è¿°ï¼Œå»ºç«‹é¢†åŸŸçŸ¥è¯†æ¡†æ¶åå†æ·±å…¥ä¸“é¢˜è®ºæ–‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¹äºåŠ©äººçš„ä¸­æ–‡åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")  # æˆ– openai:gpt-4o-mini, google_vertexai:gemini-2.5-flash\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"question\": \"ç»™æˆ‘ 3 æ¡é«˜æ•ˆè¯»è®ºæ–‡çš„è¦ç‚¹\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a0222",
   "metadata": {},
   "source": [
    "### BooleanOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¹æ„åŠ©äººçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"),\n",
    "    (\"user\", \"è¿™æ˜¯ç”¨æˆ·çš„é—®é¢˜ï¼š {topic}ï¼Œ è¯·ç”¨ yes æˆ– no æ¥å›ç­”\")\n",
    "])\n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "bool_qa_chain = prompt_template | llm | BooleanOutputParser()\n",
    "# æµ‹è¯•\n",
    "question = \"è¯·é—® 1 + 1 æ˜¯å¦ å¤§äº 2ï¼Ÿ\"\n",
    "result = bool_qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3f6b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8916",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08edb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'æé›·', 'age': '25'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"ç”¨æˆ·çš„å§“å\"),\n",
    "    ResponseSchema(name=\"age\", description=\"ç”¨æˆ·çš„å¹´é¾„\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹æå–ç”¨æˆ·ä¿¡æ¯ï¼Œå¹¶è¿”å› JSON æ ¼å¼ï¼š\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\": \"ç”¨æˆ·å«æé›·ï¼Œä»Šå¹´25å²ï¼Œæ˜¯ä¸€åå·¥ç¨‹å¸ˆã€‚\"})\n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d3c485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='name', description='ç”¨æˆ·çš„å§“å', type='string'), ResponseSchema(name='age', description='ç”¨æˆ·çš„å¹´é¾„', type='string')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2993097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // ç”¨æˆ·çš„å§“å\n",
      "\t\"age\": string  // ç”¨æˆ·çš„å¹´é¾„\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ec40a",
   "metadata": {},
   "source": [
    "## å¤åˆé“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc35424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1eb3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 'æœªæ˜ç¡®æåŠ', 'location': 'åŠ å·', 'event': 'è‹¹æœå…¬å¸å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡ï¼Œæ˜¾è‘—æå‡è®¾å¤‡ç«¯AIå¤„ç†èƒ½åŠ›ï¼Œé‡‡ç”¨å…ˆè¿›æ¶æ„æ”¯æŒæ›´å¤æ‚æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå°†åº”ç”¨äºæ–°ä¸€ä»£iPhoneåŠMacäº§å“'}\n"
     ]
    }
   ],
   "source": [
    "# ç¬¬ä¸€æ­¥ï¼šæ ¹æ®æ ‡é¢˜ç”Ÿæˆæ–°é—»æ­£æ–‡\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·æ ¹æ®ä»¥ä¸‹æ–°é—»æ ‡é¢˜æ’°å†™ä¸€æ®µç®€çŸ­çš„æ–°é—»å†…å®¹ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š\\n\\næ ‡é¢˜ï¼š{title}\"\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€ä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»å†…å®¹\n",
    "news_chain = news_gen_prompt | llm\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šä»æ­£æ–‡ä¸­æå–ç»“æ„åŒ–å­—æ®µ\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´\"),\n",
    "    ResponseSchema(name=\"location\", description=\"äº‹ä»¶å‘ç”Ÿçš„åœ°ç‚¹\"),\n",
    "    ResponseSchema(name=\"event\", description=\"å‘ç”Ÿçš„å…·ä½“äº‹ä»¶\"),\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·ä»ä¸‹é¢è¿™æ®µæ–°é—»å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç»“æ„åŒ–JSONæ ¼å¼ï¼š\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»æ‘˜è¦\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# ç»„åˆæˆä¸€ä¸ªå¤åˆ Chain\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "# è°ƒç”¨å¤åˆé“¾\n",
    "result = full_chain.invoke({\"title\": \"è‹¹æœå…¬å¸åœ¨åŠ å·å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00cc3e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='è‹¹æœå…¬å¸åœ¨åŠ å·å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡ï¼Œæ˜¾è‘—æå‡è®¾å¤‡ç«¯AIå¤„ç†èƒ½åŠ›ã€‚è¯¥èŠ¯ç‰‡é‡‡ç”¨å…ˆè¿›æ¶æ„ï¼Œèƒ½é«˜æ•ˆæ‰§è¡Œå¤æ‚æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå°†åº”ç”¨äºæ–°ä¸€ä»£iPhoneä¸Macï¼Œä¸ºç”¨æˆ·å¸¦æ¥æ›´æ™ºèƒ½ã€æµç•…çš„ä½“éªŒï¼Œè¿›ä¸€æ­¥å·©å›ºå…¶åœ¨ç§»åŠ¨è®¡ç®—é¢†åŸŸä¼˜åŠ¿ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 29, 'total_tokens': 82, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 29}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'e84dd2de-7fd6-4cb3-90a3-06bcd8014c9d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5536246f-4b63-4678-b29a-65508a2edd2a-0', usage_metadata={'input_tokens': 29, 'output_tokens': 53, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_chain.invoke({\"title\": \"è‹¹æœå…¬å¸åœ¨åŠ å·å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59acd31",
   "metadata": {},
   "source": [
    "## è‡ªå®šä¹‰èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ab2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# ä¸€ä¸ªç®€å•çš„æ‰“å°å‡½æ•°ï¼Œè°ƒè¯•ç”¨\n",
    "def debug_print(x):\n",
    "    print(\"ä¸­é—´ç»“æœï¼ˆæ–°é—»æ­£æ–‡ï¼‰:\", x)\n",
    "    return x\n",
    "\n",
    "debug_node = RunnableLambda(debug_print)\n",
    "\n",
    "# æ’å…¥ debug èŠ‚ç‚¹\n",
    "full_chain = news_chain | debug_node | summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f720c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸­é—´ç»“æœï¼ˆæ–°é—»æ­£æ–‡ï¼‰: content='è‹¹æœå…¬å¸åœ¨åŠ å·å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡ï¼Œæ˜¾è‘—æå‡è®¾å¤‡ç«¯äººå·¥æ™ºèƒ½å¤„ç†èƒ½åŠ›ã€‚è¯¥èŠ¯ç‰‡é‡‡ç”¨å…ˆè¿›æ¶æ„ï¼Œæ”¯æŒæ›´å¤æ‚çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œæœ‰æœ›åº”ç”¨äºæ–°ä¸€ä»£iPhoneåŠMacäº§å“ï¼Œä¸ºç”¨æˆ·å¸¦æ¥æ›´æ™ºèƒ½ã€é«˜æ•ˆçš„ä½“éªŒã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 29, 'total_tokens': 73, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 29}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '80136b1a-f3d3-49e5-aa4d-cb636bd4e909', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--b98c21e2-a01b-4d88-a3e1-3a331aaac8ba-0' usage_metadata={'input_tokens': 29, 'output_tokens': 44, 'total_tokens': 73, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'time': 'æœªæåŠ', 'location': 'åŠ å·', 'event': 'è‹¹æœå…¬å¸å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡ï¼Œæ˜¾è‘—æå‡è®¾å¤‡ç«¯äººå·¥æ™ºèƒ½å¤„ç†èƒ½åŠ›ï¼Œé‡‡ç”¨å…ˆè¿›æ¶æ„æ”¯æŒæ›´å¤æ‚æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå°†åº”ç”¨äºæ–°ä¸€ä»£iPhoneåŠMacäº§å“'}\n"
     ]
    }
   ],
   "source": [
    "# è°ƒç”¨å¤åˆé“¾\n",
    "result = full_chain.invoke({\"title\": \"è‹¹æœå…¬å¸åœ¨åŠ å·å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c60b1e",
   "metadata": {},
   "source": [
    "## æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d935cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "qa_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "async def demo():\n",
    "    async for chunk in qa_chain.astream({\"input\": \"ç®€å•ä»‹ç»ä¸‹ä½ è‡ªå·±\"}):\n",
    "        print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd8ff526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯å°æ™ºï¼Œä¸€åä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘çš„ä¸»è¦ä»»åŠ¡æ˜¯ä¸ºä½ æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€ååŠ©å¤„ç†æ—¥å¸¸äº‹åŠ¡ï¼Œæˆ–è€…é™ªä½ èŠå¤©ã€‚æ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œã€ç”Ÿæ´»è¿˜æ˜¯å¨±ä¹ç›¸å…³çš„é—®é¢˜ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›å¸®åŠ©ä½ ã€‚éšæ—¶æ¬¢è¿å‘æˆ‘æé—®æˆ–åˆ†äº«ä½ çš„æƒ³æ³•ï¼ ğŸ˜Š"
     ]
    }
   ],
   "source": [
    "await demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c08923",
   "metadata": {},
   "source": [
    "## å‰ç«¯å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a08aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\lc\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:276: RuntimeWarning: coroutine 'demo' was never awaited\n",
      "  def _add_custom_serialization_from_json_encoders(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_37552\\1905437079.py:20: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat = gr.Chatbot(height=480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "system_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "qa_chain = system_prompt | llm | StrOutputParser()\n",
    "\n",
    "async def chat_response(message, history):\n",
    "    partial = \"\"\n",
    "    async for chunk in qa_chain.astream({\"input\": message}):\n",
    "        partial += chunk\n",
    "        yield partial\n",
    "\n",
    "with gr.Blocks(title=\"LangChain x DeepSeek Demo\") as demo:\n",
    "    chat = gr.Chatbot(height=480)\n",
    "    msg = gr.Textbox()\n",
    "    send = gr.Button(\"å‘é€\")\n",
    "    async def on_send(m, h):\n",
    "        h = h + [(m, None)]; yield \"\", h\n",
    "        async for resp in chat_response(m, h):\n",
    "            h[-1] = (m, resp); yield \"\", h\n",
    "    send.click(on_send, [msg, chat], [msg, chat])\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbd83a",
   "metadata": {},
   "source": [
    "## æœ€å°RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43688c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®ç»™å®šä¿¡æ¯ï¼ŒLangGraph é€‚åˆä»¥ä¸‹åœºæ™¯ï¼š\n",
      "\n",
      "1. **ç¼–æ’å¤šæ­¥éª¤æµç¨‹**  \n",
      "   - é€‚ç”¨äºéœ€è¦æŒ‰é¡ºåºæˆ–æ¡ä»¶æ‰§è¡Œå¤šä¸ªæ­¥éª¤çš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°æ®å¤„ç†ã€å†³ç­–æµç¨‹æˆ–å¤æ‚æŸ¥è¯¢å¤„ç†ã€‚\n",
      "\n",
      "2. **å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**  \n",
      "   - æ”¯æŒå¤šä¸ªæ™ºèƒ½ä½“ï¼ˆå¦‚ä¸åŒåŠŸèƒ½çš„ LLM æˆ–å·¥å…·ï¼‰ååŒå·¥ä½œï¼Œé€šè¿‡çŠ¶æ€å›¾ç®¡ç†å®ƒä»¬ä¹‹é—´çš„äº¤äº’å’ŒçŠ¶æ€è½¬ç§»ã€‚\n",
      "\n",
      "3. **ç”Ÿäº§çº§ä»£ç†åº”ç”¨**  \n",
      "   - è®¾è®¡ç”¨äºæ„å»ºå¯é ã€å¯æ‰©å±•çš„ç”Ÿäº§ç¯å¢ƒç³»ç»Ÿï¼Œé›†æˆ LLMã€å·¥å…·å’Œæ£€ç´¢ç»„ä»¶ï¼Œå¹¶ç¡®ä¿å·¥ä½œæµå¯è§‚æµ‹ã€‚\n",
      "\n",
      "å¦‚æœæ¶‰åŠå…·ä½“æŠ€æœ¯ç»†èŠ‚æˆ–è¶…å‡ºä¸Šè¿°èŒƒå›´ï¼Œè¯·æä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼Œæˆ‘å°†å°½åŠ›ååŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import init_embeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "docs = [\n",
    "    \"LangChain å°† LLMã€å·¥å…·ã€æ£€ç´¢ä¸²æˆå¯è§‚æµ‹å·¥ä½œæµã€‚\",\n",
    "    \"LangGraph ç”¨çŠ¶æ€å›¾ç¼–æ’å¤šæ­¥éª¤/å¤šæ™ºèƒ½ä½“æµç¨‹ï¼Œé€‚åˆç”Ÿäº§çº§ä»£ç†ã€‚\"\n",
    "]\n",
    "splits = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=20)\\\n",
    "    .create_documents(docs)\n",
    "\n",
    "emb = init_embeddings(\"openai:text-embedding-3-small\", openai_api_key=\"sk-3H5xJ9AaAA7qUe53\", openai_api_base=\"https://chatapi.littlewheat.com/v1\")  # å¯æ¢æœ¬åœ°/å…¶ä»–å‚å•†\n",
    "vectordb = FAISS.from_documents(splits, emb)\n",
    "retriever = vectordb.as_retriever()  # ç»Ÿä¸€æ£€ç´¢æ¥å£\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä»…ä¾æ®ç»™å®š{context}å›ç­”ï¼›è‹¥ç¼ºå°‘ä¾æ®è¯·è¯´â€œæˆ‘ä¸çŸ¥é“â€ã€‚\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "\n",
    "def join_docs(docs): return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "rag = ({\"context\": retriever | join_docs, \"question\": RunnablePassthrough()}\n",
    "       | prompt | llm | StrOutputParser())\n",
    "\n",
    "print(rag.invoke( \"LangGraph é€‚åˆå“ªäº›åœºæ™¯ï¼Ÿ\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acb0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
