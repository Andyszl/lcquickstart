{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True)\n",
    "\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# print(DeepSeek_API_KEY)  # 可以通过打印查看环境变量是否正确加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f2439",
   "metadata": {},
   "source": [
    "## 调用DeepSeek的API，生成回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6450cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴认识你！我是一个人工智能助手，由先进的自然语言处理技术驱动，旨在为你提供信息、解答问题或协助完成各种任务。我可以帮助你：\n",
      "\n",
      "1. **回答问题**：涵盖科学、历史、文化、技术等多个领域。  \n",
      "2. **提供建议**：比如学习、旅行、生活技巧等。  \n",
      "3. **协助创作**：写作、翻译、生成创意内容等。  \n",
      "4. **解决问题**：逻辑分析、数学计算、编程辅助等。  \n",
      "5. **日常聊天**：分享想法或闲聊放松。\n",
      "\n",
      "我的知识截止于最新更新的数据，且会尽力提供准确、有用的信息。如果你有任何需求或疑问，随时告诉我，我会尽力帮助你！ 😊\n",
      "\n",
      "你想先从什么开始呢？\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化DeepSeek的API客户端\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 调用DeepSeek的API，生成回答\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是人工智能助手，请根据用户的问题给出回答\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请你介绍一下你自己。\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 打印模型最终的响应结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af8dd1",
   "metadata": {},
   "source": [
    "## 在 LangChain 中调用DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da338e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 方式A：显式声明 provider\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "# 方式B：合并写法（也可在其他厂商使用）\n",
    "# llm = init_chat_model(\"deepseek:deepseek-chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5605522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e1c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"你好，请你介绍一下你自己。\"\n",
    "result = model.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa90977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "你好！很高兴认识你！😊\n",
       "\n",
       "我是DeepSeek，由深度求索公司创造的AI助手。让我来详细介绍一下自己：\n",
       "\n",
       "**我的特点：**\n",
       "- 💬 我是一个纯文本模型，擅长理解和生成自然语言\n",
       "- 📁 支持文件上传功能——可以处理图像、txt、pdf、ppt、word、excel等文件，并从中读取文字信息\n",
       "- 🌐 具备联网搜索能力（需要你在Web/App中手动开启）\n",
       "- 💾 拥有128K的上下文长度，能记住我们对话中的很多细节\n",
       "\n",
       "**我能为你做什么：**\n",
       "- 回答各种问题，提供知识解答\n",
       "- 协助写作、翻译、总结文档\n",
       "- 进行逻辑推理和分析\n",
       "- 创意写作和头脑风暴\n",
       "- 学习辅导和知识解释\n",
       "- 日常聊天和情感支持\n",
       "\n",
       "**重要提醒：**\n",
       "- 我完全免费使用，没有任何收费计划\n",
       "- 目前不支持语音功能\n",
       "- 你可以通过官方应用商店下载App来使用我\n",
       "\n",
       "我的知识截止到2024年7月，会尽我所能为你提供准确、有用的帮助。有什么想聊的或需要帮助的吗？我很乐意为你服务！✨"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e33b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！很高兴认识你！😊\\n\\n我是DeepSeek，由深度求索公司创造的AI助手。让我来详细介绍一下自己：\\n\\n**我的特点：**\\n- 💬 我是一个纯文本模型，擅长理解和生成自然语言\\n- 📁 支持文件上传功能——可以处理图像、txt、pdf、ppt、word、excel等文件，并从中读取文字信息\\n- 🌐 具备联网搜索能力（需要你在Web/App中手动开启）\\n- 💾 拥有128K的上下文长度，能记住我们对话中的很多细节\\n\\n**我能为你做什么：**\\n- 回答各种问题，提供知识解答\\n- 协助写作、翻译、总结文档\\n- 进行逻辑推理和分析\\n- 创意写作和头脑风暴\\n- 学习辅导和知识解释\\n- 日常聊天和情感支持\\n\\n**重要提醒：**\\n- 我完全免费使用，没有任何收费计划\\n- 目前不支持语音功能\\n- 你可以通过官方应用商店下载App来使用我\\n\\n我的知识截止到2024年7月，会尽我所能为你提供准确、有用的帮助。有什么想聊的或需要帮助的吗？我很乐意为你服务！✨', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 10, 'total_tokens': 257, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 10}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '3e42b190-a6f5-4ddc-afc8-f87711d102f8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4dabe111-2a9d-482a-a022-de112dbc4c96-0', usage_metadata={'input_tokens': 10, 'output_tokens': 247, 'total_tokens': 257, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ba011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refusal': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.additional_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14fd76",
   "metadata": {},
   "source": [
    "## 链式调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a604b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然，高效阅读论文不仅能节省时间，还能快速抓住核心内容。以下是三条实用要点：\n",
      "\n",
      "1. **采用三遍阅读法，层层深入**  \n",
      "   - **第一遍**：快速浏览标题、摘要、图表和结论，判断论文是否相关，决定是否继续阅读。  \n",
      "   - **第二遍**：精读引言、方法、结果，标记关键信息，忽略细节推导。  \n",
      "   - **第三遍**：复现作者思路，深入理解实验设计和论证逻辑，提出批判性问题。  \n",
      "\n",
      "2. **带着问题主动阅读，避免被动接收**  \n",
      "   - 边读边问：“研究解决了什么缺口？”“方法的核心创新在哪？”“数据是否支撑结论？”  \n",
      "   - 用笔记工具（如MarginNote或表格）整理“问题-答案-疑点”，形成互动式阅读习惯。  \n",
      "\n",
      "3. **善用工具与协作，提升效率**  \n",
      "   - 用AI工具（如ChatGPT）快速解析复杂段落，或用翻译工具突破语言障碍。  \n",
      "   - 与同行讨论论文疑点，通过复述和辩论巩固理解，避免陷入思维盲区。  \n",
      "\n",
      "**附加技巧**：优先阅读高引论文和权威团队的综述，建立领域知识框架后再深入专题论文。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是乐于助人的中文助手。\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")  # 或 openai:gpt-4o-mini, google_vertexai:gemini-2.5-flash\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"question\": \"给我 3 条高效读论文的要点\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a0222",
   "metadata": {},
   "source": [
    "### BooleanOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个乐意助人的助手，请根据用户的问题给出回答\"),\n",
    "    (\"user\", \"这是用户的问题： {topic}， 请用 yes 或 no 来回答\")\n",
    "])\n",
    "\n",
    "# 直接使用模型 + 输出解析器\n",
    "bool_qa_chain = prompt_template | llm | BooleanOutputParser()\n",
    "# 测试\n",
    "question = \"请问 1 + 1 是否 大于 2？\"\n",
    "result = bool_qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3f6b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8916",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08edb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '李雷', 'age': '25'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"用户的姓名\"),\n",
    "    ResponseSchema(name=\"age\", description=\"用户的年龄\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下内容提取用户信息，并返回 JSON 格式：\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\": \"用户叫李雷，今年25岁，是一名工程师。\"})\n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d3c485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='name', description='用户的姓名', type='string'), ResponseSchema(name='age', description='用户的年龄', type='string')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2993097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // 用户的姓名\n",
      "\t\"age\": string  // 用户的年龄\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ec40a",
   "metadata": {},
   "source": [
    "## 复合链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc35424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1eb3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '未明确提及', 'location': '加州', 'event': '苹果公司发布新款AI芯片，显著提升设备端AI处理能力，采用先进架构支持更复杂机器学习任务，将应用于新一代iPhone及Mac产品'}\n"
     ]
    }
   ],
   "source": [
    "# 第一步：根据标题生成新闻正文\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\\n\\n标题：{title}\"\n",
    ")\n",
    "\n",
    "# 第一个子链：生成新闻内容\n",
    "news_chain = news_gen_prompt | llm\n",
    "\n",
    "# 第二步：从正文中提取结构化字段\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"事件发生的时间\"),\n",
    "    ResponseSchema(name=\"location\", description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\", description=\"发生的具体事件\"),\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "# 第二个子链：生成新闻摘要\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 组合成一个复合 Chain\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "# 调用复合链\n",
    "result = full_chain.invoke({\"title\": \"苹果公司在加州发布新款AI芯片\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00cc3e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='苹果公司在加州发布新款AI芯片，显著提升设备端AI处理能力。该芯片采用先进架构，能高效执行复杂机器学习任务，将应用于新一代iPhone与Mac，为用户带来更智能、流畅的体验，进一步巩固其在移动计算领域优势。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 29, 'total_tokens': 82, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 29}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'e84dd2de-7fd6-4cb3-90a3-06bcd8014c9d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5536246f-4b63-4678-b29a-65508a2edd2a-0', usage_metadata={'input_tokens': 29, 'output_tokens': 53, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_chain.invoke({\"title\": \"苹果公司在加州发布新款AI芯片\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59acd31",
   "metadata": {},
   "source": [
    "## 自定义节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ab2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 一个简单的打印函数，调试用\n",
    "def debug_print(x):\n",
    "    print(\"中间结果（新闻正文）:\", x)\n",
    "    return x\n",
    "\n",
    "debug_node = RunnableLambda(debug_print)\n",
    "\n",
    "# 插入 debug 节点\n",
    "full_chain = news_chain | debug_node | summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f720c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中间结果（新闻正文）: content='苹果公司在加州发布新款AI芯片，显著提升设备端人工智能处理能力。该芯片采用先进架构，支持更复杂的机器学习任务，有望应用于新一代iPhone及Mac产品，为用户带来更智能、高效的体验。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 29, 'total_tokens': 73, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 29}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '80136b1a-f3d3-49e5-aa4d-cb636bd4e909', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--b98c21e2-a01b-4d88-a3e1-3a331aaac8ba-0' usage_metadata={'input_tokens': 29, 'output_tokens': 44, 'total_tokens': 73, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'time': '未提及', 'location': '加州', 'event': '苹果公司发布新款AI芯片，显著提升设备端人工智能处理能力，采用先进架构支持更复杂机器学习任务，将应用于新一代iPhone及Mac产品'}\n"
     ]
    }
   ],
   "source": [
    "# 调用复合链\n",
    "result = full_chain.invoke({\"title\": \"苹果公司在加州发布新款AI芯片\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c60b1e",
   "metadata": {},
   "source": [
    "## 流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d935cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你叫小智，是一名乐于助人的助手。\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "qa_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "async def demo():\n",
    "    async for chunk in qa_chain.astream({\"input\": \"简单介绍下你自己\"}):\n",
    "        print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd8ff526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是小智，一名乐于助人的智能助手。我的主要任务是为你提供信息、解答问题、协助处理日常事务，或者陪你聊天。无论是学习、工作、生活还是娱乐相关的问题，我都会尽力帮助你。随时欢迎向我提问或分享你的想法！ 😊"
     ]
    }
   ],
   "source": [
    "await demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c08923",
   "metadata": {},
   "source": [
    "## 前端展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a08aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\lc\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:276: RuntimeWarning: coroutine 'demo' was never awaited\n",
      "  def _add_custom_serialization_from_json_encoders(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_37552\\1905437079.py:20: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat = gr.Chatbot(height=480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "system_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你叫小智，是一名乐于助人的助手。\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "qa_chain = system_prompt | llm | StrOutputParser()\n",
    "\n",
    "async def chat_response(message, history):\n",
    "    partial = \"\"\n",
    "    async for chunk in qa_chain.astream({\"input\": message}):\n",
    "        partial += chunk\n",
    "        yield partial\n",
    "\n",
    "with gr.Blocks(title=\"LangChain x DeepSeek Demo\") as demo:\n",
    "    chat = gr.Chatbot(height=480)\n",
    "    msg = gr.Textbox()\n",
    "    send = gr.Button(\"发送\")\n",
    "    async def on_send(m, h):\n",
    "        h = h + [(m, None)]; yield \"\", h\n",
    "        async for resp in chat_response(m, h):\n",
    "            h[-1] = (m, resp); yield \"\", h\n",
    "    send.click(on_send, [msg, chat], [msg, chat])\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbd83a",
   "metadata": {},
   "source": [
    "## 最小RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43688c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据给定信息，LangGraph 适合以下场景：\n",
      "\n",
      "1. **编排多步骤流程**  \n",
      "   - 适用于需要按顺序或条件执行多个步骤的任务，例如数据处理、决策流程或复杂查询处理。\n",
      "\n",
      "2. **多智能体系统**  \n",
      "   - 支持多个智能体（如不同功能的 LLM 或工具）协同工作，通过状态图管理它们之间的交互和状态转移。\n",
      "\n",
      "3. **生产级代理应用**  \n",
      "   - 设计用于构建可靠、可扩展的生产环境系统，集成 LLM、工具和检索组件，并确保工作流可观测。\n",
      "\n",
      "如果涉及具体技术细节或超出上述范围，请提供更多上下文，我将尽力协助。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import init_embeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "docs = [\n",
    "    \"LangChain 将 LLM、工具、检索串成可观测工作流。\",\n",
    "    \"LangGraph 用状态图编排多步骤/多智能体流程，适合生产级代理。\"\n",
    "]\n",
    "splits = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=20)\\\n",
    "    .create_documents(docs)\n",
    "\n",
    "emb = init_embeddings(\"openai:text-embedding-3-small\", openai_api_key=\"sk-3H5xJ9AaAA7qUe53\", openai_api_base=\"https://chatapi.littlewheat.com/v1\")  # 可换本地/其他厂商\n",
    "vectordb = FAISS.from_documents(splits, emb)\n",
    "retriever = vectordb.as_retriever()  # 统一检索接口\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"仅依据给定{context}回答；若缺少依据请说“我不知道”。\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "llm = init_chat_model(\"deepseek:deepseek-chat\")\n",
    "\n",
    "def join_docs(docs): return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "rag = ({\"context\": retriever | join_docs, \"question\": RunnablePassthrough()}\n",
    "       | prompt | llm | StrOutputParser())\n",
    "\n",
    "print(rag.invoke( \"LangGraph 适合哪些场景？\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acb0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
