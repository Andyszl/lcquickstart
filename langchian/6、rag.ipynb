{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c4986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc6fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a55def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53465ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"CHAT_API_URL\")\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0608634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://chatapi.littlewheat.com/v1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45ef2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import init_embeddings\n",
    "embeddings  = init_embeddings(\"openai:text-embedding-3-small\", openai_api_key=openai_api_key, openai_api_base=openai_api_base)  # 可换本地/其他厂商"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d9ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_read(pdf_doc):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_doc:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def vector_store(text_chunks):\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc02e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain(tools, ques):\n",
    "    llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"你是AI助手，请根据提供的上下文回答问题，确保提供所有细节，如果答案不在上下文中，请说\"答案不在上下文中\"，不要提供错误的答案\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "    \n",
    "    tool = [tools]\n",
    "    agent = create_tool_calling_agent(llm, tool, prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tool, verbose=True)\n",
    "    \n",
    "    response = agent_executor.invoke({\"input\": ques})\n",
    "    print(response)\n",
    "    st.write(\"🤖 回答: \", response['output'])\n",
    "\n",
    "def check_database_exists():\n",
    "    \"\"\"检查FAISS数据库是否存在\"\"\"\n",
    "    return os.path.exists(\"faiss_db\") and os.path.exists(\"faiss_db/index.faiss\")\n",
    "\n",
    "def user_input(user_question):\n",
    "    # 检查数据库是否存在\n",
    "    if not check_database_exists():\n",
    "        st.error(\"❌ 请先上传PDF文件并点击'Submit & Process'按钮来处理文档！\")\n",
    "        st.info(\"💡 步骤：1️⃣ 上传PDF → 2️⃣ 点击处理 → 3️⃣ 开始提问\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 加载FAISS数据库\n",
    "        new_db = FAISS.load_local(\"faiss_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "        \n",
    "        retriever = new_db.as_retriever()\n",
    "        retrieval_chain = create_retriever_tool(retriever, \"pdf_extractor\", \"This tool is to give answer to queries from the pdf\")\n",
    "        get_conversational_chain(retrieval_chain, user_question)\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ 加载数据库时出错: {str(e)}\")\n",
    "        st.info(\"请重新处理PDF文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e998f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一、前言\n",
      "  在当今AI应用开发领域，大型语言模型（LLM）已成为核心技术之一。然而，如\n",
      "何将LLM与外部数据源、工具和API有效集成，构建高效、可扩展的智能应用，仍然\n",
      "是开发者面临的挑战。为此，LangChain应运而生，提供了一个灵活、模块化的框架，帮\n",
      "助开发者构建复杂的LLM应用。\n",
      "  作为一个大模型开发者，在选择合适的框架时，应根据具体的应用需求、团队的技术\n",
      "栈以及项目的复杂度等因素进行综合考虑。LangChain、LlamaIndex和GoogleADK\n",
      "（AgentDevelopmentKit）等不同的开发框架各有优势，理解它们的特点和适用场景，\n",
      "有助于做出更合适的选择。\n",
      "1.LangChain\n",
      "\n",
      "特点：提供与LLM的集成、工具调用、记忆管理、流程控制等功能，支持多种\n",
      "数据源和模型的接入。\n",
      "\n",
      "\n",
      "优势：模块化设计，灵活性高，适用于构建复杂的LLM应用。\n",
      "\n",
      "\n",
      "适用场景：需要高度自定义和灵活性的应用，如智能客服、文档分析等。\n",
      "\n",
      "2.LlamaIndex\n",
      "\n",
      "特点：专注于检索增强生成（RAG）任务，提供数据加载、索引构建、查询引擎\n",
      "等功能。\n",
      "\n",
      "\n",
      "优势：在处理大规模数据集和高效信息检索方面表现出色。\n",
      "\n",
      "适用场景：需要高效信息检索和问答功能的应用，如知识库构建、搜索引擎等。\n",
      "\n",
      "3.GoogleADK\n",
      "\n",
      "特点：提供模块化、多智能体系统的构建能力，支持结构化和动态的工作流编排。\n",
      "\n",
      "\n",
      "优势：适用于构建复杂的多智能体系统，支持多种代理的协作和任务调度。\n",
      "\n",
      "\n",
      "适用场景：需要多智能体协作和复杂任务调度的应用，如自动化流程、智能助手\n",
      "等。\n",
      "\n",
      "二、LangChain的背景与诞生\n",
      "  LangChain由HarrisonChase于2021年提出，并于2022年作为开源项目正式发\n",
      "布。其初衷是简化大型语言模型（LLM）与外部数据源、工具和API的集成，推动\n",
      "LLM应用的快速开发。\n",
      "\n",
      "2022年：功能扩展与生态起步2022年，LangChain发布了第一个版本，提供了\n",
      "基础的提示词（Prompt）管理功能，并支持将工具（Tool）与语言模型结合，支持\n",
      "调用外部API。同时，新增了对外部数据源的支持，包括SQL数据库、NoSQL\n",
      "数据库、文件系统等，使得开发者能够将LLM与各种数据源无缝集成。\n",
      "\n",
      "2023年：快速发展与生态构建2023年，LangChain进入快速发展阶段，推出了\n",
      "多个关键功能模块，包括链（Chain）、记忆（Memory）、工具与代理（Tool&\n",
      "Agent）、检索增强生成（RAG）支持、流水线功能等，进一步增强了框架的灵活\n",
      "性和功能性。同时，LangChain加强了社区建设，吸引了大量开发者参与，生态系\n",
      "统逐步完善。\n",
      "\n",
      "\n",
      "2024年：稳定版本发布与企业化进程2024年1月8日，LangChain发布了第\n",
      "一个稳定版本（0.1.0），标志着框架进入成熟阶段。同年2月，LangChain发布\n",
      "了LangSmith，这是一个闭源的可观察性和评估平台，旨在帮助开发者跟踪、评估\n",
      "并迭代LLM应用。此外，LangChain宣布完成了由SequoiaCapital领投的2500\n",
      "万美元A轮融资。\n",
      "\n",
      "\n",
      "2025年：多智能体系统与长期部署能力2025年5月14日，LangChain推出了\n",
      "LangGraph平台，提供了托管基础设施，用于部署长期运行、有状态的AI代理。\n",
      "该平台支持多智能体协作、动态任务调度和持久化上下文管理，适用于复杂的工作\n",
      "流和多步骤任务。此外，LangChain继续扩展其生态系统，推出了多个新功能和工\n",
      "具，进一步提升了框架的能力和适用范围。\n",
      "\n",
      "三、LangChain的核心生态系统  在构建智能应用的过程中，LangChain提供了一个强大的生态系统，涵盖了从开发、\n",
      "调试、部署到可视化编排的全方位工具。以下是对LangChain核心生态系统中主要组件\n",
      "的详细介绍：\n",
      "1.LangChain：LLM应用的基础框架功能概述：\n",
      "\n",
      "模块化构建：提供Prompt模板、工具调用、记忆管理、检索增强生成（RAG）\n",
      "等模块，帮助开发者构建复杂的LLM应用。\n",
      "\n",
      "\n",
      "多模型支持：支持与OpenAI、Anthropic、HuggingFace等多种大型语言模型的集\n",
      "成。\n",
      "\n",
      "\n",
      "丰富的集成：提供与数据库、API、文件系统等外部资源的集成，扩展应用的能力。\n",
      "\n",
      "适用场景：\n",
      "\n",
      "快速原型开发。\n",
      "\n",
      "\n",
      "构建线性流程的LLM应用。\n",
      "\n",
      "\n",
      "需要灵活集成多种工具和资源的应用。\n",
      "\n",
      "2.LangGraph：复杂工作流的编排引擎\n",
      "功能概述：\n",
      "状态管理：维护应用的当前状态，支持持久化和流式处理。\n",
      "\n",
      "\n",
      "多智能体协作：支持多代理的协作和通信，适用于复杂的任务分配和执行。可与\n",
      "LangChain兼容开发使用。\n",
      "\n",
      "\n",
      "流程控制：支持循环、条件判断等复杂的流程控制。\n",
      "\n",
      "适用场景：\n",
      "\n",
      "构建复杂的多智能体系统。\n",
      "\n",
      "\n",
      "需要动态决策和状态管理的应用。\n",
      "\n",
      "\n",
      "需要高可扩展性和可靠性的生产环境。\n",
      "\n",
      "3.LangSmith：开发和生产的可观察性平台\n",
      "功能概述：\n",
      "\n",
      "追踪与调试：提供对LLM应用的追踪和调试功能，帮助开发者识别和解决问题。\n",
      "\n",
      "性能评估：评估模型和链的性能，提供优化建议。\n",
      "\n",
      "\n",
      "框架无关性：支持与多种LLM框架的集成，不仅限于LangChain。\n",
      "\n",
      "适用场景：\n",
      "\n",
      "开发阶段的调试和优化。\n",
      "\n",
      "\n",
      "生产环境中的监控和评估。\n",
      "\n",
      "\n",
      "需要高可靠性和可维护性的应用。\n",
      "\n",
      "4.LangFlow：低代码的可视化应用构建工具\n",
      "功能概述：\n",
      "\n",
      "拖拽式界面：通过可视化界面，用户可以拖拽组件，快速构建AI应用。可对比\n",
      "Dify，相比之下，LangFlow完全开源，更加灵活。\n",
      "\n",
      "\n",
      "集成LangChain：与LangChain紧密集成，支持所有主要的LLM和向量数据库。\n",
      "\n",
      "多代理支持：支持多代理的编排和对话管理。\n",
      "\n",
      "\n",
      "实时测试：提供即时测试环境，支持快速迭代和调试。\n",
      "\n",
      "适用场景：\n",
      "\n",
      "快速原型开发和MVP构建。\n",
      "\n",
      "\n",
      "需要低代码解决方案的开发者。\n",
      "\n",
      "\n",
      "教育和培训场景中的应用构建。\n",
      "\n",
      "5.LangGraphStudio：可视化调试与开发环境\n",
      "功能概述：\n",
      "\n",
      "可视化代理图：提供可视化的代理图，帮助开发者理解应用结构。\n",
      "\n",
      "\n",
      "实时交互：支持在代理运行过程中修改结果或逻辑，进行实时调试。\n",
      "\n",
      "\n",
      "代码编辑器集成：支持在代码编辑器中修改代码，并能够重新运行节点。\n",
      "适用场景：\n",
      "\n",
      "开发复杂的代理应用程序。\n",
      "\n",
      "\n",
      "需要实时调试和交互的开发环境。\n",
      "\n",
      "\n",
      "教育和培训场景中的应用开发。\n",
      "\n",
      "6.LangGraphPlatform：生产就绪的托管平台\n",
      "功能概述：\n",
      "\n",
      "托管基础设施：提供托管基础设施，用于部署长期运行、有状态的AI代理。\n",
      "\n",
      "\n",
      "多智能体协作：支持多智能体的协作和任务调度。\n",
      "\n",
      "\n",
      "持久化上下文管理：支持持久化的上下文管理，确保代理的长期运行。\n",
      "\n",
      "适用场景：\n",
      "需要长期运行和高可用性的生产环境。\n",
      "\n",
      "\n",
      "需要多智能体协作和任务调度的应用。\n",
      "\n",
      "\n",
      "需要持久化上下文管理的复杂应用。\n",
      "\n",
      "通过这些工具的协同工作，开发者可以构建、调试、部署和维护复杂的LLM应用，满\n",
      "足不同场景的需求。\n",
      "四、LangChain解决的问题与作用\n",
      "  LangChain通过标准化接口（LCEL/Tool/Retriever/Loader）、分层编排（LCEL↔\n",
      "LangGraph）、可观测与评测（LangSmith）以及生产运行时（LangGraphPlatform），把\n",
      "LLM从“强但不稳”的黑盒，变成可复用、可组合、可观测、可运营的工程化能力底座，\n",
      "显著缩短从Demo到生产的距离。\n",
      "4.1组件标准化接口：降低集成成本、摆脱厂商锁定\n",
      "  LangChain为“模型—工具—检索—管道”这几类基础构件提供了统一的抽象层，显著\n",
      "减少在不同厂商接口之间改写代码的工作量。核心在于：\n",
      "\n",
      "Runnable/LCEL标准化编排：所有链式组件统一实现Runnable接口；在此之上，\n",
      "LangChainExpressionLanguage（LCEL）用声明式语法把提示词、模型调用、解析\n",
      "器、检索器等拼装为稳定的“链”，并天然支持流式返回、异步与并行，还自动打点\n",
      "到LangSmith（需要外网，国内不方便），便于调试与回溯。官方也明确给出使\n",
      "用指引：简单编排用LCEL，涉及分支、循环、多智能体与显式状态时转用\n",
      "LangGraph。\n",
      "\n",
      "ToolCalling统一接口：不同模型厂商（OpenAI/Anthropic/Gemini等）对工具调\n",
      "用的返回结构各不相同。LangChain将其**标准化为ChatModel.bind_tools()+\n",
      "AIMessage.tool_calls**，开发者只需用@tool装饰器定义函数及其模式\n",
      "(schema)，再绑定到支持工具调用的模型即可跨厂商复用。这样避免了早期需要针\n",
      "对各家API拆additional_kwargs的脆弱写法。\n",
      "\n",
      "\n",
      "检索/向量库/文档加载的统一协议：LangChain为Retriever抽象出统一接口；向量\n",
      "库可一键转为检索器（.as_retriever()），既能对接Faiss、Pinecone等向量库，\n",
      "也能接入如Kendra、Wikipedia、API搜索等非向量后端；而DocumentLoader提\n",
      "供上百种数据源适配（本地/云存储/协作平台/社媒等），统一产出\n",
      "Document{page_content,metadata}以便后续切分、嵌入与检索。\n",
      "\n",
      "作用：统一的模型/工具/检索/编排抽象让团队可以快速换型（模型或向量\n",
      "库迁移时仅需少量改动），并把工程精力集中在业务逻辑而非粘合代码上。\n",
      "4.2复杂应用的编排：从“轻管道”到“有状态多智能体”\n",
      "  LangChain覆盖了从简单链到复杂代理系统的全谱系编排能力：\n",
      "\n",
      "LCEL适合轻量链路：如“Prompt→LLM→解析器”、“RAG的检索→重写→\n",
      "生成”等线性或轻分支流程，享受流式、异步、并行与内建追踪。官方建议复杂度\n",
      "不高时用LCEL，让代码更简洁、性能更稳。\n",
      "\n",
      "\n",
      "LangGraph处理复杂/长期/多智能体场景：当流程存在显式状态、循环、分支、\n",
      "回退、多代理协作，或需要持久化与断点续跑、人类在环(HITL)时，使用\n",
      "LangGraph。它支持耐久执行、全面记忆（短/长时），并能把图状态做检查点，\n",
      "从而在审核或人工介入后暂停/继续执行——这是生产环境智能体需要的“可控性”。\n",
      "\n",
      "作用：把简单场景交给LCEL，把复杂有状态场景交给LangGraph，既保证\n",
      "开发效率，又确保复杂系统在生产中的可控与韧性。4.3可观察性与评估：把“不确定的LLM”变成“可度量的系统”\n",
      "  LLM天生概率性强、易漂移，LangChain通过LangSmith提供从开发到上线的一\n",
      "体化可观测与评测：\n",
      "\n",
      "Tracing&Debugging：对每次调用自动记录输入、输出、耗时、代价、链路拓扑\n",
      "与工具调用细节；配合LCEL的自动打点，复杂链路也能完整复盘。\n",
      "\n",
      "\n",
      "Datasets&Evaluations：把真实用户数据或合成样例沉淀为数据集，按“数据集→\n",
      "目标函数→评测器”运行评测，比较不同Prompt/模型/参数/版本的得分，\n",
      "定位失败样例并复现；评测既支持通用正确性，也可写自定义evaluator贴合业务\n",
      "指标。\n",
      "\n",
      "作用：形成“观测—诊断—改进—再评测”闭环，让团队对质量与回归风\n",
      "险心里有数，加速从Demo到可用产品的迁移。\n",
      "4.4生产部署与管理：长跑型智能体的托管、伸缩与治理\n",
      "  从“能跑”到“能长跑”，关键在运行时与治理能力。LangChain提供LangGraph\n",
      "Platform作为生产级运行时：\n",
      "\n",
      "长运行/有状态代理的运行时：提供执行、持久化、监控、扩缩等API；可把用\n",
      "LangGraph（或其他框架）构建的代理托管成托管端点，并附带面向“助手/代理\n",
      "UX”的观点化API与集成开发者工作室。\n",
      "\n",
      "\n",
      "多部署形态：支持本地开发免费运行，生产可选云、混合、自建三种模式，满足\n",
      "合规/内网/成本等差异化诉求。\n",
      "作用：把“能工作的多智能体”稳定地跑在生产，并通过平台化能力做好\n",
      "可观测、扩缩与团队协作；结合LangSmith，可形成“开发—评测—部\n",
      "署—观测”一体化流水线。\n",
      "4.5典型落地价值（角色定位小结）\n",
      "对应用工程师：统一接口+LCEL让原型快、维护稳；检索/工具接入与切换低成本。\n",
      "对平台/架构团队：LangGraph让复杂代理可控可回放，HITL与状态持久化支撑审计与风\n",
      "控。\n",
      "对运维与质量团队：LangSmith把不确定性指标化，持续评测+线上观测锁定问题根因与回\n",
      "归。\n",
      "对生产部署：LangGraphPlatform提供可选托管路径与多形态部署，让智能体从实验室走向长\n",
      "期在线服务。\n",
      "  LangChain通过标准化接口（LCEL/Tool/Retriever/Loader）、分层编排（LCEL↔\n",
      "LangGraph）、可观测与评测（LangSmith）以及生产运行时（LangGraphPlatform），\n",
      "把LLM从“强但不稳”的黑盒，变成可复用、可组合、可观测、可运营的工程化能力底\n",
      "座，显著缩短从Demo到生产的距离。\n",
      "如果团队更偏向可视化搭建与教学演示，可引入LangFlow作为低/零代码\n",
      "的可视化编排界面（与LangChain概念一一对应，支持主流LLM/向量库），\n",
      "用于快速试验与团队协作\n",
      "五、LangChain的优势\n",
      "  LangChain具有以下优势：\n",
      "\n",
      "灵活性与扩展性：支持与多种模型、工具和数据源的集成，适应不同的应用场景。\n",
      "\n",
      "\n",
      "模块化设计：各组件功能独立，开发者可以根据需求选择使用，降低了耦合度。\n",
      "\n",
      "活跃的社区支持：拥有庞大的开发者社区，提供丰富的资源和支持，促进了生态的\n",
      "持续发展。\n",
      "\n",
      "\n",
      "企业级应用能力：支持大规模部署和管理，满足企业级应用的稳定性和可靠性要求。\n",
      "\n",
      "  这些优势使得LangChain成为构建LLM应用的有力工具，广泛应用于智能客服、\n",
      "文档分析、代码生成等领域。\n",
      "六、LangChain的未来发展方向\n",
      "  LangChain的未来发展将聚焦以下方向：\n",
      "跨领域集成：扩展更多领域的工具集成，如物联网设备、图像处理模型等，构建更丰富的应用\n",
      "场景。\n",
      "智能任务调度与优化：增强对任务调度、资源优化等方面的支持，提高系统效率和响应速度。\n",
      "增强的记忆与上下文管理：提升记忆机制的智能性，支持更长时间、跨任务的上下文跟踪，提\n",
      "供更连贯的用户体验。\n",
      "生态系统的进一步发展：吸引更多开发者和企业参与，推出更多工具和插件，丰富生态系统，\n",
      "提升开发效率。\n",
      "通过这些发展，LangChain将继续推动LLM应用的发展，成为开发者构建智能应用的\n",
      "重要平台。\n",
      "  LangChain的发展历程和生态系统的不断完善，展示了其在构建智能应用方面的强大\n",
      "能力。随着未来功能的不断拓展，LangChain无疑将成为AI应用开发领域的重要工具。\n"
     ]
    }
   ],
   "source": [
    "# 修改文件路径\n",
    "pdf_files = ['D:/workself/project/LangChain/lcquickstart/LangChain入门.pdf'\n",
    "]\n",
    "\n",
    "# 调用函数\n",
    "raw_text = pdf_read(pdf_files)\n",
    "print(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc47208",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = get_chunks(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314ece90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02efdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
